{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eminent01/AMMI-WORK/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cshoS5vcGfAD"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "oZGs1hIDGjtc",
        "outputId": "d23842ed-d84c-494e-c2ea-5cc6d131b2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 128\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "8cazzlAfSKT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path= \"/content/drive/MyDrive/Cat_Dog_Images/Images\""
      ],
      "metadata": {
        "id": "-JCwHG-vGrq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata.to_csv(\"/content/drive/MyDrive/Cat_Dog_Images/metadata_ok.csv\", index= False)"
      ],
      "metadata": {
        "id": "ilc678PzLIJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata= \"/content/drive/MyDrive/Cat_Dog_Images/metadata_ok.csv\""
      ],
      "metadata": {
        "id": "KfyrO6ErLyDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2K1s-pZAfBtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.read_csv(metadata, header= 1)"
      ],
      "metadata": {
        "id": "TDDleTULOSEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataSet(Dataset):\n",
        "    def __init__(self, metadata, dir_root,transform= None):\n",
        "        self.dir_root= dir_root\n",
        "        self.annotations= pd.read_csv(metadata, header= 1)\n",
        "        self.transform= transform\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        fileName= self.annotations.iloc[idx, 0]\n",
        "        im= os.path.join(self.dir_root, fileName)\n",
        "        img = Image.open(im).convert(\"RGB\")\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        classCategory= self.annotations.iloc[idx, 1]\n",
        "        return img, im, classCategory"
      ],
      "metadata": {
        "id": "DHpNgihkHG68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#      transforms.RandomResizedCrop(224),\n",
        "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n"
      ],
      "metadata": {
        "id": "Rj9TaULHKyRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= CustomDataSet(metadata, path, transform= transform)"
      ],
      "metadata": {
        "id": "-C2BA9q_J-yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "rSbpc65PMRNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "n6Bc4evIMcrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(data[10][1])"
      ],
      "metadata": {
        "id": "aObliB75NeWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_display(img):\n",
        "    # img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    return npimg"
      ],
      "metadata": {
        "id": "zxPi8JhUPENF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z1f2Y7muN9vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 16\n",
        "train_size= 0.8\n",
        "train_size= int(train_size*len(data))\n",
        "val_size = len(data) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(data, [train_size, val_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "F_osCir3PEzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0][0].shape"
      ],
      "metadata": {
        "id": "FAWaVwbVSsiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, _, j in train_loader:\n",
        "#   print(i)"
      ],
      "metadata": {
        "id": "TlfueVcPQP83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, img, labels= dataiter.next()\n",
        "bird_type = {0: 'cat', 1: 'dog'}\n",
        "# Viewing data examples used for training\n",
        "fig, axis = plt.subplots(2, 2, figsize=(15, 10))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    with torch.no_grad():\n",
        "        image, label= images[i], labels[i]\n",
        "        ax.imshow(img_display(image)) # add image\n",
        "        \n",
        "        ax.set(title = f\"{bird_type[label.item()]}\")"
      ],
      "metadata": {
        "id": "l6vU1IXEQWsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(val_loader)\n",
        "images, img, labels= dataiter.next()\n",
        "bird_type = {0: 'cat', 1: 'dog'}\n",
        "# Viewing data examples used for training\n",
        "fig, axis = plt.subplots(2, 2, figsize=(15, 10))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    with torch.no_grad():\n",
        "        image, label= images[i], labels[i]\n",
        "        ax.imshow(img_display(image)) # add image\n",
        "        \n",
        "        ax.set(title = f\"{bird_type[label.item()]}\")"
      ],
      "metadata": {
        "id": "rdrOOTvJQlCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader"
      ],
      "metadata": {
        "id": "Wqry1uHERh1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= torchvision.models.resnet50(pretrained= True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 1, bias = True),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "BlFRXXWEQpTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion= nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, weight_decay=1.0)\n",
        "num_epochs= 30"
      ],
      "metadata": {
        "id": "yc6oynhdQ6Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train(model, criterion, train_loader, val_loader, optimizer, num_epochs, device):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "\n",
        "    val_loss = []\n",
        "    val_acc = []\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    val_loss_min = np.Inf\n",
        "    total_step = len(train_loader)\n",
        "    \n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "    \n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "    \n",
        "    # Loop over epochs.\n",
        "    # for epoch in range(num_epochs):\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      running_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "        \n",
        "      # Loop over data.\n",
        "      for data, _, target in train_loader:\n",
        "            \n",
        "          # Forward pass.\n",
        "          output =model(data.to(device))\n",
        "          loss = criterion(output.to(device).squeeze(), target.to(device).float())\n",
        "          # loss.requires_grad = True\n",
        "          # print(loss)\n",
        "          # Backward pass.\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss +=loss.item()\n",
        "          pred = output.argmax(dim=1, keepdim=True)\n",
        "          correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "          total += target.size(0)\n",
        "          \n",
        "      print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
        "            epoch, running_loss/total_step),\n",
        "      )\n",
        "      \n",
        "      train_acc.append(100 * correct/total)\n",
        "      train_loss.append(running_loss/total_step)\n",
        "\n",
        "\n",
        "\n",
        "      # Validation\n",
        "      batch_loss = 0\n",
        "      total_t = 0\n",
        "      correct_t = 0\n",
        "      with torch.no_grad():\n",
        "          model.eval()\n",
        "          for data_t,_, target_t in val_loader:\n",
        "              data_t,target_t = data_t.to(device),target_t.to(device)\n",
        "              outputs_t = model(data_t)\n",
        "              loss_t = criterion(outputs_t.squeeze(),target_t.float())\n",
        "              batch_loss+=loss.item()\n",
        "              _,pred_t = torch.max(outputs_t,dim=1)\n",
        "              correct_t += torch.sum(pred_t==target_t).item()\n",
        "              total_t += target_t.size(0)\n",
        "          val_acc.append(100 * correct_t/total_t)\n",
        "          val_loss.append(batch_loss/len(val_loader))\n",
        "          network_achieve = batch_loss < val_loss_min\n",
        "        \n",
        "\n",
        "          if network_achieve:\n",
        "              val_loss_min = batch_loss\n",
        "              torch.save(model.state_dict(), '/content/model_ok.ckpt')\n",
        "\n",
        "              print('The best model is detected')\n",
        "\n",
        "\n",
        "    # torch.save(model.state_dict(), 'model.pth')\n",
        "    percent = 100. * correct / len(train_loader.dataset)\n",
        "    return model, percent, val_loss, val_acc, train_loss, train_acc"
      ],
      "metadata": {
        "id": "95x59gDYam1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trained, percent, val_loss, val_acc, train_loss, train_acc= train(model, criterion, train_loader, val_loader, optimizer, num_epochs, device)"
      ],
      "metadata": {
        "id": "kjYXX0WSauzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Training results: Loss\")\n",
        "plt.plot(val_loss,label='val_loss')\n",
        "plt.plot(train_loss, label=\"train_loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QpKZ93i-au6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Training results: Acc\")\n",
        "plt.plot(val_acc,label='val_acc')\n",
        "plt.plot(train_acc, label=\"train_acc\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "uQKtmLCybp31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc"
      ],
      "metadata": {
        "id": "yJCbpZDFbz2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc"
      ],
      "metadata": {
        "id": "0Aw4K8T-FLn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model (2 conv layers)\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = torch.nn.Linear(9408, 1, bias=True)\n",
        "        self.m = nn.Sigmoid()\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)  \n",
        "        # print(out.shape) \n",
        "        out = self.fc(out)\n",
        "        out= self.m(out)\n",
        "        return out\n",
        "\n",
        "# instantiate CNN model\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "9ryFlqoMb6BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trained, percent, val_loss, val_acc, train_loss, train_acc= train(model, criterion, train_loader, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "E7lk7ILIb6Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Training results: Loss\")\n",
        "plt.plot(val_loss,label='val_loss')\n",
        "plt.plot(train_loss, label=\"train_loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "0nIY0TIGb6GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jy7aGi8bb6I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.title(\"Training results: Loss\")\n",
        "plt.plot(val_loss,label='val_loss')\n",
        "plt.plot(train_loss, label=\"train_loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "U8IbEsjbb6Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add a function form predict in local (predict.py)"
      ],
      "metadata": {
        "id": "w0_g7TwXfjd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q-tCRLHnfjgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C3upWiwWfji1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Xb1sup_fjl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_train, train_loss= train(model, criterion, train_loader, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "id": "ssV4sYefS2Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VXkXuFAfSB4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, val_loss= test(model_train, val_loader)"
      ],
      "metadata": {
        "id": "rRWAermiS7P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss"
      ],
      "metadata": {
        "id": "koL95CACaS0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Training results\")\n",
        "plt.plot(val_loss,label='val_loss')\n",
        "plt.plot(train_loss, label=\"train_loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ozrKB-N6Xjdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "def image_transform(imagepath):\n",
        "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "    image = Image.open(imagepath)\n",
        "    imagetensor = test_transforms(image)\n",
        "    return imagetensor\n",
        "\n",
        "\n",
        "def predict(imagepath, verbose=False):\n",
        "    if not verbose:\n",
        "        warnings.filterwarnings('ignore')\n",
        "    model_path = './model/model_ok.pth'\n",
        "    try:\n",
        "        checks_if_model_is_loaded = type(model)\n",
        "    except:\n",
        "        model = models.resnet50()\n",
        "    model.eval()\n",
        "    #summary(model, input_size=(3,244,244))\n",
        "    if verbose:\n",
        "        print(\"Model Loaded..\")\n",
        "    image = image_transform(imagepath)\n",
        "    image1 = image[None,:,:,:]\n",
        "    # ps= torch.exp(model(image1))\n",
        "    ps= model(image1)\n",
        "    topconf, topclass = ps.topk(1, dim=1)\n",
        "    # print(ps)\n",
        "    if topclass.item() == 1:\n",
        "        return {'class':'dog','confidence':str(topconf.item())}\n",
        "    else:\n",
        "        return {'class':'cat','confidence':str(topconf.item())}\n",
        "\n",
        "\n",
        "\n",
        "image_path= \"Image_path\"\n",
        "# print(predict('data/Images/image_name'))\n",
        "print(Image.open(image_path))\n",
        "print(predict(image_path))"
      ],
      "metadata": {
        "id": "sE73PeZiUEmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}